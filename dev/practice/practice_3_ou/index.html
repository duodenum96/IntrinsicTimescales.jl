<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Ornstein-Uhlenbeck Process as a Generative Model for ACF · IntrinsicTimescales.jl</title><meta name="title" content="Ornstein-Uhlenbeck Process as a Generative Model for ACF · IntrinsicTimescales.jl"/><meta property="og:title" content="Ornstein-Uhlenbeck Process as a Generative Model for ACF · IntrinsicTimescales.jl"/><meta property="twitter:title" content="Ornstein-Uhlenbeck Process as a Generative Model for ACF · IntrinsicTimescales.jl"/><meta name="description" content="Documentation for IntrinsicTimescales.jl."/><meta property="og:description" content="Documentation for IntrinsicTimescales.jl."/><meta property="twitter:description" content="Documentation for IntrinsicTimescales.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../home/">IntrinsicTimescales.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../home/">Getting Started</a></li><li><span class="tocitem">Practice</span><ul><li><a class="tocitem" href="../practice_intro/">Practice</a></li><li><a class="tocitem" href="../practice_1_acf/">Building the Autocorrelation Function</a></li><li><a class="tocitem" href="../practice_2_acw/">Autocorrelation Windows</a></li><li class="is-active"><a class="tocitem" href>Ornstein-Uhlenbeck Process as a Generative Model for ACF</a></li><li><a class="tocitem" href="../practice_4_psd/">Dealing with Oscillatory Artifacts using Fourier Transformation</a></li><li><a class="tocitem" href="../practice_5_bayesian/">Bayesian Estimation of Intrinsic Timescales</a></li></ul></li><li><a class="tocitem" href="../../theory/theory/">Theory</a></li><li><span class="tocitem">Implementation</span><ul><li><a class="tocitem" href="../../acw/">Model-Free Timescale Estimation</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Simulation Based Timescale Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../simbasedinference/">Overview</a></li><li><a class="tocitem" href="../../one_timescale/">One Timescale Model</a></li><li><a class="tocitem" href="../../one_timescale_with_missing/">One Timescale Model with Missing Data</a></li><li><a class="tocitem" href="../../one_timescale_and_osc/">One Timescale Model with Oscillations</a></li><li><a class="tocitem" href="../../one_timescale_and_osc_with_missing/">One Timescale Model with Oscillations and Missing Data</a></li><li><a class="tocitem" href="../../fit_parameters/">Model Fitting and Parameters</a></li><li><a class="tocitem" href="../../fit_result/">Results</a></li></ul></li></ul></li><li><a class="tocitem" href="../../">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Practice</a></li><li class="is-active"><a href>Ornstein-Uhlenbeck Process as a Generative Model for ACF</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Ornstein-Uhlenbeck Process as a Generative Model for ACF</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/duodenum96/IntrinsicTimescales.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/duodenum96/IntrinsicTimescales.jl/blob/master/docs/src/practice/practice_3_ou.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Ornstein-Uhlenbeck-Process-as-a-Generative-Model-for-ACF"><a class="docs-heading-anchor" href="#Ornstein-Uhlenbeck-Process-as-a-Generative-Model-for-ACF">Ornstein-Uhlenbeck Process as a Generative Model for ACF</a><a id="Ornstein-Uhlenbeck-Process-as-a-Generative-Model-for-ACF-1"></a><a class="docs-heading-anchor-permalink" href="#Ornstein-Uhlenbeck-Process-as-a-Generative-Model-for-ACF" title="Permalink"></a></h1><h3 id="(Or-Mommy,-Where-Do-the-ACFs-Come-From?)"><a class="docs-heading-anchor" href="#(Or-Mommy,-Where-Do-the-ACFs-Come-From?)">(Or Mommy, Where Do the ACFs Come From?)</a><a id="(Or-Mommy,-Where-Do-the-ACFs-Come-From?)-1"></a><a class="docs-heading-anchor-permalink" href="#(Or-Mommy,-Where-Do-the-ACFs-Come-From?)" title="Permalink"></a></h3><p>Despite popular belief, ACFs aren&#39;t delivered by storks. So far, we just assumed that they exist and calculated ACW metrics from them. This is where we start building a more comprehensive theory. I will keep the math to a minimum and whenever I explain math, I will supplement it with code so that you can play with to get some intuition. </p><p>Let&#39;s get right into it. You have some data and from that data you can calculate an autocorrelation function. But what is the most minimal, simplest ground truth that can generate the data that you see? This is a very hard question and the discipline of theoretical neuroscience tries to answer it (<a href="https://neuronaldynamics.epfl.ch/">Neuronal Dynamics</a> by Gerstner et al. is an excellent starting place for the curious). An easier question is what is the simplest ground truth that can generate the <em>autocorrelation function</em> that you observe in the data? Then we can ask how can we think of the ACF beyond a bunch of numbers. One way to think about ACF is to think of it as an exponential decay function. Here is the math + code:</p><p class="math-container">\[\textrm{ACF}(l) = e^{-\frac{l}{\tau}}\]</p><pre><code class="language-julia hljs">using Plots
dt = 0.0001 # time resolution
lags = (0:2500) * dt # x axis
tau_short = 0.01 # short timescale
tau_long = 0.03 # long timescale
acf_short = exp.(-lags ./ tau_short)
acf_long = exp.(-lags ./ tau_long)
plot(lags, acf_short, label=&quot;Short Timescale ACF&quot;)
plot!(lags, acf_long, label=&quot;Long Timescale ACF&quot;)</code></pre><p><img src="../assets/practice_3_1.svg" alt/></p><p>Compare this with the ACFs we plotted in the previous tutorials. An exponential decay function is an abstraction of the ACF. In the equation above, we represent the lags with <span>$l$</span> and timescale with <span>$\tau$</span>. As expected, as I increase <span>$\tau$</span> (<code>tau</code>), the ACF decays slower. You can eyeball the ACW-50. We can do better than eyeballing. Let&#39;s do high-school math to get the ACW-50. Remember the definition: ACW-50 is the lag where ACF crosses 0.5:</p><p class="math-container">\[e^{-\frac{l}{\tau}} = 0.5\]</p><p>We need to solve this for <span>$l$</span>. Remember that the inverse of an exponential is a logarithm. Taking the logarithm of both sides:</p><p class="math-container">\[\log{e^{-\frac{l}{\tau}}} = \log{0.5} \\

-\frac{l}{\tau} = \log{0.5} \\ 

l = -\tau \log{0.5} \\

l = -\tau \log{2^{-1}} \\

l = \tau \log{2} \\

\textrm{ACW-50} = \tau \log{2}\]</p><p>That&#39;s it! We effectively showed that ACW-50 is just the timescale or decay rate of the autocorrelation function up to a constant which is <span>$\log{2}$</span>. This is good, but the data we have is not just an autocorrelation function. It is the whole time series. The next step is to figure out the generative model for the time-series which gives this autocorrelation function. I will explain the birds and bees of this in the <a href="../../theory/theory/">Theory</a> section but even pure practicioners need to know a minimum of theory to understand what they practice. The minimum of theory is the mysterious thing that I shied away from explaining properly, the Ornstein-Uhlenbeck (OU) process. The function <a href="../../#IntrinsicTimescales.OrnsteinUhlenbeck.generate_ou_process-Tuple{Union{Real, Vector{&lt;:Real}}, Vararg{Real, 4}}"><code>generate_ou_process</code></a> that we used again and again without explaining. No more. Here is the OU:</p><p class="math-container">\[\frac{dx(t)}{dt} = -\frac{1}{\tau} x(t) + \xi (t)\]</p><p>This equation is called a differential equation. On the left hand side, you have a derivative (the <span>$\frac{d}{dt}$</span> term). <span>$t$</span> denotes time here. You have the rate of change of something (<span>$x$</span>) with respect to time. That is, how does <span>$x$</span> change when time changes. <span>$x$</span> is your dynamic variable or your observable: what you observe in data. To see how it changes, look at the right hand side. The first term is <span>$-\frac{1}{\tau} x(t)$</span>. <span>$\tau$</span> is the timescale. This term ensures that your <span>$x$</span> always moves to 0. To see how, note that <span>$\tau$</span> is always positive. If you give a positive number to <span>$x$</span>, the <span>$-$</span> sign will make sure that <span>$x$</span> decreases with time. If <span>$x$</span> reduces too much, becomes negative, then the <span>$-$</span> sign will again ensure that <span>$x$</span> increases to move it towards zero because if you put a <span>$-$</span> sign in front of a negative number, it becomes positive (as in <span>$-(-3) = +3$</span>). The final term, <span>$\xi (t)$</span> ensures that your <span>$x$</span> doesn&#39;t get stuck at zero. This term is called white noise: it is a random number drawn from a Gaussian distribution. How does this all relate to timescales? Let&#39;s ask the question: how fast <span>$x$</span> approaches zero? Well, this is determined by <span>$\frac{1}{\tau}$</span> in front of it. Higher the <span>$\tau$</span>, slower the approach because <span>$\frac{1}{\textrm{big number}}$</span> is a small number and vice versa. If you feel uncomfortable with the mathematics I present here, I invite you to pull up a pen and paper and plug in different numbers. It&#39;ll become clear. There is no better way to build intuition other than grinding your way through intuition and <a href="https://www.youtube.com/watch?v=PLxXC-V8wLs">forcing your way through its wooden doors with a battering ram</a>. </p><p>Back to <code>generate_ou_process</code>. What this function does is that it solves this equation. What does it mean to solve an equation? There are a number of ways to approach an equation of this type: one can take averages of both sides, calculate moments, use a Fokker-Planck approach, apply perturbation theory via Martin-Siggia-Rose-De Dominicis-Janssen path integral, apply Fourier analysis, use Ito or Stratonovich calculus. <code>generate_ou_process</code> takes a numerical approach: it assigns a random initial number as a starting condition and moves <span>$x$</span> forward in small steps according to the equation. Under the hood, it uses the amazing <a href="https://docs.sciml.ai/DiffEqDocs/stable/">DifferentialEquations.jl</a> library which is optimized to the bone, this is why it is fast. Since we solve the equation for <span>$x(t)$</span>, the end result is a time-series. Under ideal conditions (that is, sufficiently enough data), if you calculate the autocorrelation function of this time-series, you will get an exponential decay function of the same type above. Let&#39;s test this with the tools that we are hopefully familiar with now:</p><pre><code class="language-julia hljs">using IntrinsicTimescales, Statistics
sd = 1.0
duration = length(lags) * dt # match the number of lags
num_trials = 100
n_lags = length(lags)
data_short_ts = generate_ou_process(tau_short, sd, dt, duration, num_trials)
data_long_ts = generate_ou_process(tau_long, sd, dt, duration, num_trials)
# average over trials to get a less noisy ACF
acf_numerical_short = mean(comp_ac_fft(data_short_ts), dims=1)[:]
acf_numerical_long = mean(comp_ac_fft(data_long_ts), dims=1)[:]
p1 = plot(lags, acf_short, label=&quot;Analytical ACF&quot;, title=&quot;Short Timescale&quot;)
plot!(p1, lags, acf_numerical_short, label=&quot;Numerical ACF&quot;)
p2 = plot(lags, acf_long, label=&quot;Analytical ACF&quot;, title=&quot;Long Timescale&quot;)
plot!(p2, lags, acf_numerical_long, label=&quot;Numerical ACF&quot;)
plot(p1, p2, size=(800,400))</code></pre><p><img src="../assets/practice_3_2.svg" alt/></p><p>Note that the numerical ACF estimate decays consistenly faster than the analytical ground truth. The difference between the numerical estimate and analytical one increases as timescale increases. This is a limitation of finite data. As long as your data is finite and has a sampling rate that is not infinitesimally small, you will underestimate the INT. We will address this problem in the [final tutorial of Practice]. </p><p>The good thing is even though we are underestimating the INT, the ACF of the long timescale process still decays slower than the short timescale one. </p><p>This theoretical knowledge motivates two more ACW types. The first one is the lag where ACF crosses <span>$1/e$</span>. In IntrinsicTimescales.jl, this is called <code>acweuler</code> (or ACW-e) but I&#39;m not sure if there is a generic name for it in the literature. The math: </p><p class="math-container">\[e^{-\frac{l}{\tau}} = \frac{1}{e} \\

\log{e^{-\frac{l}{\tau}}} = \log{\frac{1}{e}} \\

-\frac{l}{\tau} = -1 \\

l = \tau\]</p><p>Assuming that your autocorrelation function is a perfect exponential decay, then calculating ACW-e directly gives you the timescale <span>$\tau$</span>. Alternatively, we can fit an exponential decay function to our autocorrelation function and get the decay rate. IntrinsicTimescales.jl uses the Julia package <a href="https://docs.sciml.ai/NonlinearSolve/stable/">NonlinearSolve.jl</a> for the fitting. In IntrinsicTimescales.jl, this metric is called <code>tau</code>. Note that by default, IntrinsicTimescales.jl cuts the tail of the ACF before fitting. Remember that the ACF estimate gets noisier as we have less and less data for longer lags. If we keep all the ACF, we might fit to the noise as well. By default, the lag where the ACF is cut is <code>1.1*acw0</code>. You can change this by the parameter <code>n_lags</code>. In the code example below, I show the two methods. </p><pre><code class="language-julia hljs">fs = 1 / dt
acwresults_short = acw(data_short_ts, fs, acwtypes=[:acweuler, :tau], average_over_trials=true)
acwresults_long = acw(data_long_ts, fs, acwtypes=[:acweuler, :tau], average_over_trials=true)
acw_e_short, acw_tau_short = acwresults_short.acw_results
acw_e_long, acw_tau_long = acwresults_long.acw_results
println(&quot;Short timescale: $(tau_short)&quot;)
# 0.01
println(&quot;ACW-e estimate of short timescale: $(acw_e_short)&quot;)
# 0.0091
println(&quot;Curve-fitting estimate of short timescale: $(acw_tau_short)&quot;)
# 0.0088
println(&quot;Long timescale: $(tau_long)&quot;)
# 0.03
println(&quot;ACW-e estimate of long timescale: $(acw_e_long)&quot;)
# 0.0214
println(&quot;Curve-fitting estimate of long timescale: $(acw_tau_long)&quot;)
# 0.02</code></pre><p>So far, we always assumed that the ACF is a nice exponential decay. This is rarely the case for EEG/MEG data where oscillatory brain activity (alpha oscillations for example) makes a considerable impact on ACF. We will learn how to deal with it in the next section. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../practice_2_acw/">« Autocorrelation Windows</a><a class="docs-footer-nextpage" href="../practice_4_psd/">Dealing with Oscillatory Artifacts using Fourier Transformation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 9 April 2025 07:03">Wednesday 9 April 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
